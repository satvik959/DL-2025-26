{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDSnVOfnBG3BXN/sNy52Q4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik959/DL-2025-26/blob/main/WEEK5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaallj-bFntl",
        "outputId": "5ec1c43a-d195-4d14-c43c-a9760ee68f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n",
            "Using Colab cache for faster access to the 'stroke-prediction-dataset' dataset.\n",
            "Dataset path: /kaggle/input/stroke-prediction-dataset\n",
            "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
            "0   9046    Male  67.0             0              1          Yes   \n",
            "1  51676  Female  61.0             0              0          Yes   \n",
            "2  31112    Male  80.0             0              1          Yes   \n",
            "3  60182  Female  49.0             0              0          Yes   \n",
            "4   1665  Female  79.0             1              0          Yes   \n",
            "\n",
            "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
            "0        Private          Urban             228.69  36.6  formerly smoked   \n",
            "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
            "2        Private          Rural             105.92  32.5     never smoked   \n",
            "3        Private          Urban             171.23  34.4           smokes   \n",
            "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
            "\n",
            "   stroke  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "path = kagglehub.dataset_download(\"fedesoriano/stroke-prediction-dataset\")\n",
        "\n",
        "print(\"Dataset path:\", path)\n",
        "\n",
        "df = pd.read_csv(path + \"/healthcare-dataset-stroke-data.csv\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop ID column (not useful for prediction)\n",
        "df = df.drop(columns=[\"id\"])\n",
        "\n",
        "# Handle missing values (BMI has missing values)\n",
        "df['bmi'] = df['bmi'].fillna(df['bmi'].mean())\n",
        "\n",
        "# Convert categorical columns to numerical\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(\"stroke\", axis=1)\n",
        "y = df[\"stroke\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling (VERY IMPORTANT for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "H5JpOESVJsEM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_l2_model(input_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     input_shape=(input_dim,),\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(32, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(1, activation='sigmoid')   # Binary output\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_l2 = build_l2_model(X_train.shape[1])\n",
        "\n",
        "model_l2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFxVoWEqJxwT",
        "outputId": "f2a2db37-184e-465b-dd5b-dfee086139d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_l2.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Qtz5woJ4qr",
        "outputId": "5774af2d-466c-4306-acd2-737b3b404677"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9043 - loss: 0.9946 - val_accuracy: 0.9548 - val_loss: 0.5546\n",
            "Epoch 2/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.5017 - val_accuracy: 0.9548 - val_loss: 0.3578\n",
            "Epoch 3/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.3325 - val_accuracy: 0.9548 - val_loss: 0.2679\n",
            "Epoch 4/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.2607 - val_accuracy: 0.9548 - val_loss: 0.2252\n",
            "Epoch 5/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.2189 - val_accuracy: 0.9548 - val_loss: 0.2004\n",
            "Epoch 6/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1967 - val_accuracy: 0.9548 - val_loss: 0.1864\n",
            "Epoch 7/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1760 - val_accuracy: 0.9548 - val_loss: 0.1782\n",
            "Epoch 8/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1809 - val_accuracy: 0.9548 - val_loss: 0.1730\n",
            "Epoch 9/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1710 - val_accuracy: 0.9548 - val_loss: 0.1700\n",
            "Epoch 10/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1709 - val_accuracy: 0.9548 - val_loss: 0.1672\n",
            "Epoch 11/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1617 - val_accuracy: 0.9548 - val_loss: 0.1660\n",
            "Epoch 12/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.1580 - val_accuracy: 0.9548 - val_loss: 0.1651\n",
            "Epoch 13/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1685 - val_accuracy: 0.9548 - val_loss: 0.1655\n",
            "Epoch 14/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1694 - val_accuracy: 0.9548 - val_loss: 0.1641\n",
            "Epoch 15/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1732 - val_accuracy: 0.9548 - val_loss: 0.1635\n",
            "Epoch 16/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1607 - val_accuracy: 0.9548 - val_loss: 0.1639\n",
            "Epoch 17/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1448 - val_accuracy: 0.9548 - val_loss: 0.1636\n",
            "Epoch 18/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9553 - loss: 0.1572 - val_accuracy: 0.9548 - val_loss: 0.1637\n",
            "Epoch 19/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9566 - loss: 0.1552 - val_accuracy: 0.9548 - val_loss: 0.1627\n",
            "Epoch 20/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1625 - val_accuracy: 0.9548 - val_loss: 0.1623\n",
            "Epoch 21/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9587 - loss: 0.1534 - val_accuracy: 0.9548 - val_loss: 0.1627\n",
            "Epoch 22/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9580 - loss: 0.1582 - val_accuracy: 0.9548 - val_loss: 0.1634\n",
            "Epoch 23/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1609 - val_accuracy: 0.9548 - val_loss: 0.1634\n",
            "Epoch 24/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9579 - loss: 0.1548 - val_accuracy: 0.9548 - val_loss: 0.1623\n",
            "Epoch 25/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9502 - loss: 0.1763 - val_accuracy: 0.9548 - val_loss: 0.1627\n",
            "Epoch 26/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9589 - loss: 0.1489 - val_accuracy: 0.9548 - val_loss: 0.1621\n",
            "Epoch 27/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9499 - loss: 0.1707 - val_accuracy: 0.9548 - val_loss: 0.1619\n",
            "Epoch 28/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1565 - val_accuracy: 0.9548 - val_loss: 0.1622\n",
            "Epoch 29/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9590 - loss: 0.1585 - val_accuracy: 0.9548 - val_loss: 0.1619\n",
            "Epoch 30/30\n",
            "\u001b[1m103/103\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.1821 - val_accuracy: 0.9548 - val_loss: 0.1624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the input data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# ğŸ”¹ FIX: Reshape 28x28 images into 784-length vectors\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define a simple model with L2 regularization\n",
        "def build_l2_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     input_shape=(784,),\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_l2 = build_l2_model()\n",
        "\n",
        "model_l2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model_l2.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model_l2.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYYGKSyNv8k",
        "outputId": "4bc78b69-d1f2-4f29-a091-416aa621f568"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8273 - loss: 1.2602 - val_accuracy: 0.9219 - val_loss: 0.5387\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.5477 - val_accuracy: 0.9171 - val_loss: 0.4988\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.4771 - val_accuracy: 0.9362 - val_loss: 0.4393\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.4381 - val_accuracy: 0.9477 - val_loss: 0.3854\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.4086 - val_accuracy: 0.9407 - val_loss: 0.3851\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.3821 - val_accuracy: 0.9518 - val_loss: 0.3589\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.3674 - val_accuracy: 0.9514 - val_loss: 0.3356\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.3480 - val_accuracy: 0.9528 - val_loss: 0.3266\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.3375 - val_accuracy: 0.9582 - val_loss: 0.3099\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.3326 - val_accuracy: 0.9519 - val_loss: 0.3245\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.3503\n",
            "Test accuracy: 0.9510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# ğŸ”¹ Reshape to (samples, 28, 28, 1) for augmentation\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ğŸ”¹ Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# ğŸ”¹ Build Model (with L2 regularization)\n",
        "def build_l2_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_l2 = build_l2_model()\n",
        "\n",
        "model_l2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Train using augmented data\n",
        "history = model_l2.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=32),\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // 32\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Evaluate model\n",
        "test_loss, test_acc = model_l2.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU4gQ5EEOo5b",
        "outputId": "2bbba505-45a2-47cc-9495-111f20efea0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17ms/step - accuracy: 0.6706 - loss: 1.6883 - val_accuracy: 0.9328 - val_loss: 0.6712\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8652 - loss: 0.8325 - val_accuracy: 0.9449 - val_loss: 0.5597\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.8882 - loss: 0.7176 - val_accuracy: 0.9401 - val_loss: 0.5224\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8963 - loss: 0.6600 - val_accuracy: 0.9346 - val_loss: 0.5259\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.8988 - loss: 0.6217 - val_accuracy: 0.9468 - val_loss: 0.4582\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.9022 - loss: 0.6003 - val_accuracy: 0.9494 - val_loss: 0.4417\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.9045 - loss: 0.5852 - val_accuracy: 0.9429 - val_loss: 0.4344\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.9061 - loss: 0.5707 - val_accuracy: 0.9476 - val_loss: 0.4280\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.9053 - loss: 0.5603 - val_accuracy: 0.9387 - val_loss: 0.4288\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9063 - loss: 0.5474 - val_accuracy: 0.9501 - val_loss: 0.4130\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.4378\n",
            "Test accuracy: 0.9501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Flatten\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ğŸ”¹ Shared Layer\n",
        "shared_dense = Dense(64, activation='relu')\n",
        "\n",
        "# Two inputs\n",
        "input1 = Input(shape=(784,))\n",
        "input2 = Input(shape=(784,))\n",
        "\n",
        "# Apply SAME layer (parameter sharing)\n",
        "encoded1 = shared_dense(input1)\n",
        "encoded2 = shared_dense(input2)\n",
        "\n",
        "# Merge\n",
        "merged = Concatenate()([encoded1, encoded2])\n",
        "output = Dense(10, activation='softmax')(merged)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train (using same data twice just for demo)\n",
        "model.fit([x_train, x_train], y_train,\n",
        "          epochs=5,\n",
        "          batch_size=256,\n",
        "          validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate([x_test, x_test], y_test)\n",
        "print(\"Test accuracy (Parameter Sharing):\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaivtCjNQG_g",
        "outputId": "79808e93-2010-4293-df2d-af3fe7e133b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7134 - loss: 1.0128 - val_accuracy: 0.9275 - val_loss: 0.2674\n",
            "Epoch 2/5\n",
            "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9231 - loss: 0.2692 - val_accuracy: 0.9432 - val_loss: 0.2069\n",
            "Epoch 3/5\n",
            "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.2014 - val_accuracy: 0.9503 - val_loss: 0.1783\n",
            "Epoch 4/5\n",
            "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1615 - val_accuracy: 0.9559 - val_loss: 0.1581\n",
            "Epoch 5/5\n",
            "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.1365 - val_accuracy: 0.9601 - val_loss: 0.1434\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1548\n",
            "Test accuracy (Parameter Sharing): 0.9595000147819519\n"
          ]
        }
      ]
    }
  ]
}